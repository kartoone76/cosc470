{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb67599",
   "metadata": {},
   "source": [
    "# HW 2 - Simple Neural Networks\n",
    "\n",
    "Part 1: In this first real coding assignment, you will initially explore the operation of a single perceptron (more for historical value than for modern usefulness) and a single Sigmoid neuron to implement the \"real world\" example of going to a cheese festival.\n",
    "\n",
    "Part 2: In the second part, you will switch over to using the author's code to complete a full neural network that can recognize handwritten digits. You will train and run the network monitoring both how long it takes to train AND the test accuracy once training is complete.\n",
    "\n",
    "Part 3: In the third part, you will experiment with hyper-parameters such as the number of epochs, the batch size, and the learning rate. Again, you will monitor the training time and the test accuracy after training is complete.\n",
    "\n",
    "Part 4: In the final part, you will experiment with the network structure itself by changing the number of neurons in the hidden layer. You will again report the training time and test accuracy, but this time you will also report the evaluation time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d25619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "class Neuron:\n",
    "  def __init__(self, w, b):\n",
    "    self.w = w\n",
    "    self.b = b\n",
    "\n",
    "  @abstractmethod\n",
    "  def output(self, x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d446292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Perceptron(Neuron):\n",
    "  def __init__(self, w, b):\n",
    "    super().__init__(w, b)\n",
    "\n",
    "  \"\"\"\n",
    "    x: list of inputs ... must be same length as w\n",
    "    return 0 or 1 based on classic perceptron calculation weighted sum of inputs plus bias must be strictly greater than 0 to produce a 1 otherwise return a 0\n",
    "  \"\"\"\n",
    "  def output(self, x):\n",
    "    z = 0\n",
    "    for i in range(len(self.w)):\n",
    "      z = z + self.w[i]*x[i]\n",
    "    z = z + self.b\n",
    "    return 0 if z <= 0 else 1\n",
    "\n",
    "class SigmoidNeuron(Neuron):\n",
    "  def __init__(self, w, b):\n",
    "    super().__init__(w, b)\n",
    "\n",
    "  \"\"\"\n",
    "    x: list of inputs ... must be same length as w\n",
    "    return 0 or 1 based on classic perceptron calculation weighted sum of inputs plus bias must be strictly greater than 0 to produce a 1 otherwise return a 0\n",
    "  \"\"\"\n",
    "  def output(self, x):\n",
    "    z = 0\n",
    "    for i in range(len(self.w)):\n",
    "      z = z + self.w[i]*x[i]\n",
    "    z = z + self.b\n",
    "    return 1/(1+math.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f43d4a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0.9933071490757153\n",
      "0.2689414213699951\n"
     ]
    }
   ],
   "source": [
    "# PART 1a - instantiate a single Perceptron with the weights described in Chapter 1 for going to the festival. Then print out the output of calling the \"output\" function on that neuron with three combinations of inputs for the weather, girlfiend, and public transit inputs.\n",
    "p = Perceptron([6,2,2], -5)\n",
    "x = [1, 1, 1]\n",
    "a = p.output(x)\n",
    "print(a)\n",
    "x = [0, 1, 1]\n",
    "a = p.output(x)\n",
    "print(a)\n",
    "\n",
    "# PART 2b - repeat Part1a, but this time use a SigmoidNueron instead. Compare the output with Part 1a and explain in a comment how this part using a SigmoidNeuron could still give you the \"right\" answer about whether to go or not.\n",
    "m = SigmoidNeuron([6,2,2], -5)\n",
    "x = [1, 1, 1]\n",
    "a = m.output(x)\n",
    "print(a)\n",
    "x = [0, 1, 1]\n",
    "a = m.output(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54278848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/cosc470\n",
      "/workspaces/cosc470\n",
      "Cloning into 'nn'...\n",
      "remote: Enumerating objects: 63, done.\u001b[K\n",
      "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
      "remote: Total 63 (delta 30), reused 28 (delta 28), pack-reused 21 (from 1)\u001b[K\n",
      "Receiving objects: 100% (63/63), 16.43 MiB | 54.98 MiB/s, done.\n",
      "Resolving deltas: 100% (31/31), done.\n"
     ]
    }
   ],
   "source": [
    "# PART 2 - run the code below to download your author's code and then train and evaluate the network. ****Make note of the total training time and test accuracy****\n",
    "#%cd /content \n",
    "%cd \"/workspaces/cosc470/\" \n",
    "!pwd\n",
    "!git clone \"https://github.com/MichalDanielDobrzanski/DeepLearningPython\" nn\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8862b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'nn'\n",
      "/workspaces/cosc470/nn\n",
      "50000\n",
      "10000\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.05 0.1  0.39 0.48 0.03 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.13 0.59 0.81 0.98 0.98 0.98 0.57 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.16 0.59 0.95 0.98 0.99 0.88 0.82 0.98 0.91 0.16 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.06 0.59 0.93 0.98 0.98 0.98 0.84 0.12 0.14 0.98 0.98 0.23 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.38 0.98 0.98 0.98 0.98 0.85 0.11 0.   0.14 0.98 0.98 0.23 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.71 0.98 0.98 0.86 0.65 0.12 0.   0.   0.3  0.98 0.98 0.23 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.5  0.23 0.09 0.   0.   0.   0.   0.39 0.98 0.98 0.23 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.61 0.98 0.98 0.23 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.43 0.47 0.48 0.47 0.79 0.98 0.76 0.01 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.04 0.21 0.7  0.99 0.99 1.   0.99 0.99 0.89 0.14 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.02 0.21 0.89 0.98 0.95 0.89 0.66 0.95 0.98 0.98 0.9  0.46 0.02 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.02 0.3  0.98 0.98 0.49 0.23 0.   0.07 0.81 0.98 0.98 0.98 0.98 0.34 0.03 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.02 0.53 0.98 0.98 0.7  0.06 0.   0.08 0.79 0.99 0.96 0.5  0.68 0.98 0.98 0.72 0.26 0.19 0.19 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.01 0.53 0.98 0.94 0.41 0.07 0.   0.21 0.78 0.98 0.84 0.25 0.   0.05 0.28 0.64 0.94 0.98 0.98 0.87 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.41 0.98 0.95 0.34 0.07 0.29 0.66 0.95 0.98 0.49 0.11 0.   0.   0.   0.   0.   0.35 0.7  0.7  0.14 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.9  0.98 0.96 0.8  0.84 0.98 0.98 0.98 0.48 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.81 0.98 0.98 0.98 0.98 0.7  0.45 0.14 0.02 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.05 0.36 0.56 0.47 0.09 0.02 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# load the data into memory (training_data and test_data numpy arrays)\n",
    "%cd nn\n",
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "training_data = list(training_data)\n",
    "test_data = list(test_data)\n",
    "print(len(training_data))\n",
    "print(len(test_data))\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=400)\n",
    "firstimage = np.reshape(training_data[5][0],(28,28))\n",
    "firstimage_r = np.round(firstimage, decimals=2)\n",
    "\n",
    "print(firstimage_r)\n",
    "print(training_data[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "812336cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "[[0.44907995]\n",
      " [0.81396429]\n",
      " [0.00707575]\n",
      " [0.90054124]\n",
      " [0.95473681]\n",
      " [0.99452011]\n",
      " [0.7195206 ]\n",
      " [0.93552346]\n",
      " [0.00797964]\n",
      " [0.31355213]]\n",
      "Epoch 0 : 9091 / 10000\n",
      "Epoch 1 : 9190 / 10000\n",
      "Epoch 2 : 9310 / 10000\n",
      "Epoch 3 : 9381 / 10000\n",
      "Epoch 4 : 9385 / 10000\n",
      "[[5.79162915e-06]\n",
      " [3.36437449e-05]\n",
      " [1.00423774e-05]\n",
      " [2.70432798e-03]\n",
      " [2.72294294e-02]\n",
      " [2.09932846e-05]\n",
      " [3.91087475e-06]\n",
      " [6.34732296e-03]\n",
      " [6.96106525e-03]\n",
      " [9.82534650e-01]]\n"
     ]
    }
   ],
   "source": [
    "# default run with default hyperparameters - 20 epochs, batch size of 10, and learning rate of 3.0\n",
    "\n",
    "import importlib\n",
    "import network\n",
    "importlib.reload(network)\n",
    "net = network.Network([784, 30, 10])\n",
    "print(training_data[800][1])\n",
    "print(net.feedforward(training_data[800][0]))\n",
    "\n",
    "#print(net.weights)\n",
    "#print(net.biases)\n",
    "net.SGD(training_data, 5, 10, 3.0, test_data=test_data)\n",
    "\n",
    "print(net.feedforward(training_data[800][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b205e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3 - experiment with the hyperparameters ... try the following combinations\n",
    "# Varying the number of epochs: 5, 10, 15, 30 (see below)\n",
    "# 5, 10, 3.0\n",
    "# 10, 10, 3.0\n",
    "# 15, 10, 3.0\n",
    "# 30, 10, 3.0\n",
    "\n",
    "# Varying the batch size: 5, 20, 30\n",
    "# 20, 5, 3.0\n",
    "# 20, 20, 3.0\n",
    "# 20, 30, 3.0\n",
    "\n",
    "# Varying the learning rate: 2.5, 3.5, 4.0\n",
    "# 20, 10, 2.5\n",
    "# 20, 10, 3.5\n",
    "# 20, 10, 4.0\n",
    "\n",
    "\n",
    "# After all 10 RUNS plus your original run with the defaults (20, 10, 3.0), plot your timing results and final test accuracy in a single chart using matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4 - experiment with network structure, just try three different configurations\n",
    "# [784, 10, 10], [784, 50, 10], and [784, 100, 10]\n",
    "\n",
    "# After these 3 runs, plot your training timing results, test accuracy, AND evaluation timing\n",
    "# To measure the evaluation time, manually test 100 samples from the test dataset, measure how long that takes and divide by 100 to get a per/image evaluate rate\n",
    "\n",
    "# Use Matplotlib to plot ALL THREE results (training time, test accuracy, and evaluation rate) on three different axes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
